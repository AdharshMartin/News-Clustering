pub_8a7c2d312f6647a6b6be50ea7372703f     newsdata.io


pip install --user -U nltk
pip install -U sentence-transformers
pip install hf_xet
pip install hdbscan
vs_BuildTools.exe
pip install umap-learn




from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.decomposition import TruncatedSVD



import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
stop_words_final = stopwords.words('english')
stop_words_final.remove('not')


df = pd.read_csv("data-tsv-file/data-news.tsv", sep="\t")


vectorizer = TfidfVectorizer(stop_words=stop_words_final,max_features=3000)
X = vectorizer.fit_transform(df["text"])

svd = TruncatedSVD(n_components=100, random_state=42)
X_reduced = svd.fit_transform(X)


cluster_num = 5
kmean = KMeans(n_clusters=cluster_num,random_state=42)
df["cluster"] = kmean.fit_predict(X_reduced)

df = df[["cluster","text", "headline", "description","source","url","date"]]
df.to_csv("data-tsv-file/data-news.tsv",sep='\t',index=False)
